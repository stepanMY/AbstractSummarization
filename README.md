# AbstractSummarization
NLP проект про суммаризацию.

Основная задача: научиться генерировать заголовки статей по их абстрактам. В качестве обучающего датасета были выбраны заголовки и абстракты выпускных квалификационных работ студентов НИУ ВШЭ.

Проект можно разделить на четыре основных стадии:
1. Сбор и обработка данных
2. Осмотр данных
3. Обучение моделей
4. Выкладка лучшей модели в *продакшн* и разработка веб-приложения

## Сбор и обработка данных
НИУ ВШЭ публикует краткую информацию о работе каждого студента на сайте - https://www.hse.ru/edu/vkr. 

Данные я собирал асинхронно (asyncio, aiohttp), с помощью парсера из [parsing/parser.py](parsing/parser.py). Было выгружено 73 тысячи записей, вся процедура заняла \~60 минут.

Собранные курсовые я очищал от пропусков, тэгов, табов, переносов строк и пустых строк. После удаления записей с отсутствующими абстрактами в датасете осталось 69 тысяч наблюдений, после удаления слишком коротких абстрактов - 66 тысяч, после фильтрации по языку (оставлял только русский) - 65 тысяч.

Ноутбук с описанием сбора данных: [парсинг данных](https://colab.research.google.com/drive/1HhptktsglrPZ-gTdaDmcOfd8jM933zuK);

Ноутбук с описанием преобработки данных: [предобработка данных](https://colab.research.google.com/drive/1oIpHwZv_5Z4ARI-MbuCbt6j4fCSIgJsw);
## Осмотр данных
[EDA полученного датасета](https://colab.research.google.com/drive/1YkXKjw4-5CxDShISPwKttq03HxXEFzVQ)
## Обучение моделей
sample text
## Выкладка лучшей модели в *продакшн* и разработка веб-приложения
tbd
