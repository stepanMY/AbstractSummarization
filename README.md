# AbstractSummarization
NLP проект про суммаризацию.

Основная задача: научиться генерировать заголовки статей по их абстрактам. В качестве обучающего датасета были выбраны заголовки и абстракты выпускных квалификационных работ студентов НИУ ВШЭ.

Проект можно разделить на четыре основных стадии:
1. Сбор и обработка данных
2. Осмотр данных
3. Обучение моделей
4. Выкладка лучшей модели в *продакшн* и разработка веб-приложения

## Сбор и обработка данных
НИУ ВШЭ публикует краткую информацию о работе каждого студента на сайте - https://www.hse.ru/edu/vkr. 

Данные я собирал асинхронно (asyncio, aiohttp), с помощью парсера из [parsing/parser.py](parsing/parser.py). Было выгружено 73 тысячи записей, вся процедура заняла \~60 минут.

Собранные курсовые я очищал от пропусков, тэгов, табов, переносов строк и пустых строк. После удаления записей с отсутствующими абстрактами в датасете осталось 69 тысяч наблюдений, после удаления слишком коротких абстрактов - 66 тысяч, после фильтрации по языку (оставлял только русский) - 65 тысяч.

Ноутбук с описанием сбора данных: [парсинг данных](https://colab.research.google.com/drive/1HhptktsglrPZ-gTdaDmcOfd8jM933zuK);

Ноутбук с описанием преобработки данных: [предобработка данных](https://colab.research.google.com/drive/1oIpHwZv_5Z4ARI-MbuCbt6j4fCSIgJsw);
## Осмотр данных
Провел небольшой обзор данных. Из интересного:
1. Среднее число слов в заголовке - 9
2. Среднее число слов в абстракте - 150
3. Среднее отношение слов в заголовке к словам в абстракте - 0.06
4. 2018 год - единственный год, когда количество работ не выросло. Полагаю, что это связано с политическим кризисом 2014 года (отложенный в 4 года эффект)
5. Больше всего в датасете ВКР студентов программ: экономика (4400), менеджмент (3500), юриспруденция (3500), бизнес-информатика (2500), дизайн (1400)

Ноутбук: [EDA полученного датасета](https://colab.research.google.com/drive/1YkXKjw4-5CxDShISPwKttq03HxXEFzVQ)
## Обучение моделей
sample text
## Выкладка лучшей модели в *продакшн* и разработка веб-приложения
tbd
